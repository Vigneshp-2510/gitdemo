{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "orig_nbformat": 4,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.7.9 64-bit"
  },
  "interpreter": {
   "hash": "2477ad58ea0fabfad8a9abd93eeb78f42da272d8f9bd878188fd1171b935f0f3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "import pandas as pd\r\n",
    "import datetime\r\n",
    "import json\r\n",
    "import sys\r\n",
    "import time\r\n",
    "  \r\n",
    "\r\n",
    "# def insert_record(array_value):\r\n",
    "#     insert_query = \"INSERT INTO rsi.drugs_dispensed(practice_name, dw_practice_id, filename, file_timestamp, etl_timestamp, dos, provider, patient, chart, procedure, eye, lot) VALUES \"+','.join(array_value[:])+\"  on conflict (dos,provider,patient,chart,procedure,eye) do update set filename=Excluded.filename, file_timestamp=Excluded.file_timestamp, lot=Excluded.lot\"\r\n",
    "#     print(insert_query)\r\n",
    "\r\n",
    "# def writeCsv(data, filename):\r\n",
    "#     print('write csv...')\r\n",
    "#     dbCount = 0\r\n",
    "#     errorCount = 0\r\n",
    "#     csvCount = 0\r\n",
    "#     if data:\r\n",
    "#         csvCount = len(data)\r\n",
    "#         print('filename: ', filename, 'count: ', len(data))\r\n",
    "#         insert_values = []\r\n",
    "#         for d in data:\r\n",
    "#             insert_values.append(data[d])\r\n",
    "#         print(insert_values)\r\n",
    "#         insert_record(insert_values)\r\n",
    "#         # with open(csvpath + filename +'.csv','w') as csvfile:\r\n",
    "#         #     for d in data:\r\n",
    "#         #         insert_values.append(data[d])\r\n",
    "#         #         csvfile.write(data[d]+\"\\n\")\r\n",
    "#         # try:\r\n",
    "#         #     dbCount = insert_record(insert_values)\r\n",
    "#         #     #mv_file = os.popen('mv '+filepath+f+' '+processed_path)\r\n",
    "#         #     mv_file = os.popen('rm '+filepath+\"'\"+f+\"'\")\r\n",
    "#         # except:\r\n",
    "#         #     print('file: '+f+' failed to load into database')\r\n",
    "#         # print ('>>  Processed '+f+' at '+str(datetime.datetime.now()))\r\n",
    "\r\n",
    "\r\n",
    "\r\n",
    "\r\n",
    "\r\n",
    "\r\n",
    "\r\n",
    "\r\n",
    "\r\n",
    "\r\n",
    "\r\n",
    "# def dedupRecords(data, filename):\r\n",
    "#     dedupData = {}\r\n",
    "#     errorData = {}\r\n",
    "#     for d in data:\r\n",
    "#         # print(d)\r\n",
    "#         try:\r\n",
    "#             dedupData[time.strftime('%Y-%m-%d %H:%M:%S', time.gmtime(d['Enc Date']/1000.0))+'|'+str(d['Doctor'])+'|'+str(d['Patient'])+'|'+str(int(d['Chart #']))+'|'+str(d['Procedure'])+'|'+str(d['Eye'])] = '($$'+d['practice_name']+'$$,$$'+str(d['dw_practice_id'])+'$$,$$'+str(d['filename'])+'$$,$$'+time.strftime('%Y-%m-%d %H:%M:%S', time.gmtime(d['file_timestamp']/1000.0))+'$$,$$'+time.strftime('%Y-%m-%d %H:%M:%S', time.gmtime(d['etl_timestamp']/1000.0))+'$$,$$'+time.strftime('%Y-%m-%d %H:%M:%S', time.gmtime(d['Enc Date']/1000.0))+'$$,$$'+d['Doctor']+'$$,$$'+d['Patient']+'$$,$$'+str(int(d[u'Chart #']))+'$$,$$'+d['Procedure']+'$$,$$'+d['Eye']+'$$,$$'+str(d['Lot #'])+'$$)'\r\n",
    "#         except:\r\n",
    "#             e = sys.exc_info()[0]\r\n",
    "#             errorData[time.strftime('%Y-%m-%d %H:%M:%S', time.gmtime(d['Enc Date']/1000.0))+'|'+str(d['Doctor'])+'|'+str(d['Patient'])+'|'+str(d['Chart #'])+'|'+str(d['Procedure'])+'|'+str(d['Eye'])] = '($$'+d['practice_name']+'$$,$$'+str(d['dw_practice_id'])+'$$,$$'+str(d['filename'])+'$$,$$'+time.strftime('%Y-%m-%d %H:%M:%S', time.gmtime(d['file_timestamp']/1000.0))+'$$,$$'+time.strftime('%Y-%m-%d %H:%M:%S', time.gmtime(d['etl_timestamp']/1000.0))+'$$,$$'+time.strftime('%Y-%m-%d %H:%M:%S', time.gmtime(d['Enc Date']/1000.0))+'$$,$$'+d['Doctor']+'$$,$$'+d['Patient']+'$$,$$'+str(d[u'Chart #'])+'$$,$$'+d['Procedure']+'$$,$$'+d['Eye']+'$$,$$'+str(d['Lot #'])+'$$,$$'+str(e)+'$$)'\r\n",
    "#     #print(dedupData)\r\n",
    "#     writeCsv(dedupData,filename)\r\n",
    "\r\n",
    "\r\n",
    "\r\n",
    "\r\n",
    "csvdata = {}\r\n",
    "# if f not in exceptfile:\r\n",
    "tuples = ()\r\n",
    "# print (f)\r\n",
    "pd=pd.read_excel('Sample1.xlsx', header=4, index_col=0, skipfooter=1)\r\n",
    "pd1 = pd.dropna(how='all')\r\n",
    "pd1 = pd1.reset_index()\r\n",
    "pd1 = pd1.dropna(how='all',axis = 1)\r\n",
    "pd1['filename'] = 'sample_data'\r\n",
    "\r\n",
    "pd1['file_timestamp'] = datetime.datetime.now()\r\n",
    "pd1['etl_timestamp'] = datetime.datetime.now()\r\n",
    "pd1['practice_name'] = 'RSI'\r\n",
    "pd1['dw_practice_id'] = 20\r\n",
    "s=pd1.columns.values\r\n",
    "fheader = ['practice_name', 'dw_practice_id', 'filename', 'file_timestamp', 'etl_timestamp', u'Enc Date', 'Doctor', 'Patient', 'Chart #', 'Procedure', 'Eye', 'Lot #']\r\n",
    "print()\r\n",
    "print(fheader)\r\n",
    "# if list(pd1.columns.values) == fheader:\r\n",
    "#     print(\"yes\")\r\n",
    "# else:\r\n",
    "#     missingheader = list(set(fheader) - set(list(pd1.columns.values)))\r\n",
    "#     #print(missingheader)\r\n",
    "#     if len(missingheader)>2:\r\n",
    "#         pd = pd.read_excel('', index_col=0, skipfooter=1)\r\n",
    "#         pd1 = pd.dropna(how='all')\r\n",
    "#         pd1 = pd1.reset_index()\r\n",
    "#         pd1 = pd1.dropna(how='all',axis = 1)\r\n",
    "#         pd1['filename'] = f\r\n",
    "#         pd1['file_timestamp'] = datetime.datetime.fromtimestamp(os.path.getmtime(filepath+f))\r\n",
    "#         pd1['etl_timestamp'] = datetime.datetime.now()\r\n",
    "#         pd1['practice_name'] = practice_name\r\n",
    "#         pd1['dw_practice_id'] = dw_practice_id\r\n",
    "#     else:\r\n",
    "#         for h in missingheader:\r\n",
    "#             pd1[h] = None\r\n",
    "s3://newgen-process-test/010220_AB_Krueger20200103131254.xlsx\r\n",
    "#         #print(pd1)\r\n",
    "#     subset = pd1[fheader]\r\n",
    "#     print()\r\n",
    "#     print()\r\n",
    "#     print(subset)\r\n",
    "#     value=json.loads(subset.to_json(orient='records'))\r\n",
    "    # dedupRecords(json.loads(subset.to_json(orient='records')), 'sample')\r\n",
    "    #print(value)\r\n",
    "\r\n",
    "\r\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      "['practice_name', 'dw_practice_id', 'filename', 'file_timestamp', 'etl_timestamp', 'Enc Date', 'Doctor', 'Patient', 'Chart #', 'Procedure', 'Eye', 'Lot #']\n"
     ]
    }
   ],
   "metadata": {}
  }
 ]
}